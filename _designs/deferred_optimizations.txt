DEFERRED OPTIMIZATIONS
======================
Status: Future Enhancement
Source: Extracted from refactoring_tasks.txt (2026-01-24)

These tasks were deferred because they require substantial changes and careful testing.

================================================================================
TASK: Improve progress tracking granularity
================================================================================

Files: pef/gui/main_window.py, pef/cli/main.py

Problem:
Progress is directory-level. When processing large directories, the UI appears
stuck because progress only updates between directories, not between files.

Current behavior:
- Progress updates every 100 JSON files processed
- No indication of progress within a single large album/directory

Proposed fix:
- Add file-level progress updates within each directory
- Consider a two-level progress indicator (directories + files)
- May need to restructure the progress callback to support nested progress

Considerations:
- Must balance update frequency vs performance overhead
- GUI updates should still be batched to avoid UI lag
- CLI progress bar (tqdm) may need different handling than GUI

================================================================================
TASK: Optimize double-pass directory scanning
================================================================================

File: pef/core/scanner.py (lines 54-56)

Problem:
The FileScanner walks the directory tree twice:
1. First pass: Count total files for progress calculation
2. Second pass: Actually scan and index files

This doubles the I/O time for large directory trees.

Current code pattern:
```python
# First pass - count
for root, dirs, files in os.walk(path):
    total += len(files)

# Second pass - scan
for root, dirs, files in os.walk(path):
    # process files
```

Proposed fix:
Single pass with deferred progress updates:
```python
# Single pass - scan and count simultaneously
files_found = []
for root, dirs, files in os.walk(path):
    for f in files:
        files_found.append(process_file(f))
        if len(files_found) % 100 == 0:
            on_progress(len(files_found), -1, "Scanning...")  # -1 = unknown total

# After scan complete, update with final count
on_progress(len(files_found), len(files_found), "Scan complete")
```

Considerations:
- Progress callbacks need to handle unknown totals (-1 or None)
- GUI progress bar should show indeterminate state initially
- tqdm supports unknown totals with `total=None`
- May want to estimate total based on early sampling

Alternative approach:
- Use os.scandir() instead of os.walk() for better performance
- Cache directory structure for subsequent operations
- Consider async/parallel scanning for very large trees

================================================================================
